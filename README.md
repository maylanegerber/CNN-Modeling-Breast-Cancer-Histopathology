## Introduction
In this study I used a dataset of breast Histopathology Images with pre-labeled cancerous/infected or non-cancerous/non-infected cells. The original dataset is from the xx institute and contains 277524 images, 198738 of which are healthy and 78786 infected scans.

Due to the large nature of the dataset I only used a 5% sample in order to ensure that the runtime of my models wouldnâ€™t be too large. Once sampled for I has a total of 9792 non-infected images and 3817 infected ones. Next I split my data into training and validation sets which gave me the following totals of images per category:
Total training normal images: 7833
Total training infected images: 3054
Total validation normal images: 1959
Total validation infected images: 763

## One-Layer CNN (No Dropout):
First started with a one layer One-Layer CNN (No Dropout). To classify breast cancer images as normal or infected, I utilized a convolutional neural network (CNN) architecture designed to balance simplicity and computational efficiency. Given the relatively small input size of 50x50x3 (width, height, and RGB channels), I opted for a one-layer CNN as an initial model to assess baseline performance. The single convolution block consists of a Conv2D layer with 32 filters and a kernel size of 3x3, followed by a MaxPooling2D layer to reduce spatial dimensions, thereby capturing essential features while minimizing overfitting. I chose the ReLU activation function to introduce non-linearity, and the subsequent flattening step converts the 2D feature map into a 1D tensor suitable for the dense layers. A fully connected layer with 256 neurons and ReLU activation captures high-level patterns before the final output layer, which uses a sigmoid activation for binary classification. To optimize the model, I used the Adam optimizer, known for its adaptive learning rate, and the binary cross-entropy loss function, appropriate for two-class problems. The images were rescaled by 1/255 to normalize pixel values, improving training stability. Additionally, I utilized a batch size of 32, balancing memory usage and training speed, and ran the model for 15 epochs to allow sufficient learning without overfitting. The model was trained using the ImageDataGenerator for real-time data augmentation, with separate generators for training and validation to maintain data consistency and comparability.

The model likely overfits after around 7 epochs, as evidenced by the increasing gap between training and validation accuracy and the rising validation loss. This is common in simple models trained for too many epochs. Introducing techniques like dropout, early stopping, or using a more complex model might mitigate this overfitting. Additionally, data augmentation or a more sophisticated CNN architecture might help improve generalization.

## Two-Layer CNN (With Dropout):
To improve the performance and mitigate overfitting observed in the previous model, I designed a more robust CNN architecture with two convolutional layers and incorporated dropout. The input layer processes 50x50x3 images, reflecting the size and RGB channels of the breast cancer images. The first convolution block consists of a Conv2D layer with 32 filters of size 3x3, followed by a MaxPooling2D layer to reduce the spatial dimensions while preserving key features. The second convolution block increases the filter count to 64, leveraging deeper feature extraction, followed by another MaxPooling2D layer. After flattening the output from the convolutional layers, a fully connected dense layer with 256 neurons and ReLU activation learns high-level representations. To address overfitting, I included a dropout layer with a rate of 0.5, which randomly drops half of the neurons during training, forcing the model to learn more general features. The output layer uses a sigmoid activation function for binary classification (normal vs. infected). The model was compiled using the Adam optimizer, chosen for its adaptive learning rate, and binary cross-entropy loss, appropriate for binary outcomes. The data was preprocessed by normalizing pixel values to the [0, 1] range using ImageDataGenerator. Training and validation data were loaded in batches of 32, and the model was trained for 15 epochs to balance learning progression with the risk of overfitting.

The addition of a second convolutional layer and dropout has notably improved the model's ability to generalize, as seen by the reduced gap between training and validation accuracy and the more stable validation loss curve. This indicates that the model is less prone to overfitting, likely due to the added model complexity and the dropout regularization. The fluctuations in validation accuracy early on suggest that the model initially struggled to learn generalized patterns but eventually stabilized as training progressed.

## Four-Layer CNN (With Dropout):
To further enhance the model's ability to capture complex patterns and improve generalization, I developed a deeper CNN architecture with four convolutional layers and dropout. The model starts by processing the 50x50x3 input images through four consecutive convolution blocks, each increasing in filter count (32, 64, 128, 256) to progressively learn more abstract and detailed features. After each convolutional layer, a MaxPooling operation reduces the spatial dimensions, preserving essential patterns while minimizing computational complexity. To prevent overfitting, a dropout layer with a rate of 0.5 is incorporated after the fourth convolution block. The flattened feature map is then passed through a dense layer with 512 neurons and ReLU activation to capture high-level representations before the final output layer, which uses a sigmoid activation for binary classification (normal vs. infected). The model is compiled with the Adam optimizer for adaptive learning and binary cross-entropy loss, while images are normalized by rescaling pixel values to the range [0, 1]. This architecture, with its increased depth and dropout regularization, aims to balance model complexity with generalization.

The increased model complexity with four convolutional layers and dropout has significantly improved the model's capacity to capture complex patterns. The dropout layer helped mitigate overfitting compared to previous models. The occasional spikes in validation loss and accuracy indicate that the model might still be sensitive to certain batch variations or noise in the data. Despite these fluctuations, the overall trend indicates a well-trained model with improved generalization compared to previous attempts. Fine-tuning the dropout rate or implementing early stopping could help smooth out the fluctuations.
