## Introduction
In this study, I utilized a dataset of breast histopathology images containing pre-labeled cancerous/infected and non-cancerous/non-infected cells. The original dataset comprised a total of 277,524 images, including 198,738 healthy and 78,786 infected scans.
Given the large size of the dataset, I opted to use a 5% sample to reduce runtime and make model training more efficient. This sampling resulted in 9,792 non-infected images and 3,817 infected images. I then split the sampled data into training and validation sets, yielding the following distribution of images per category:
Total training normal images: 7,833
Total training infected images: 3,054
Total validation normal images: 1,959
Total validation infected images: 763
This approach ensured a balanced and manageable dataset size while maintaining sufficient representation of both healthy and infected cases.

## One-Layer CNN (No Dropout)
First I started with a one layer One-Layer CNN (No Dropout). To classify breast cancer images as normal or infected, I utilized a convolutional neural network architecture designed to balance simplicity and computational efficiency. Given the relatively small input size of 50x50x3, I opted for a one-layer CNN as an initial model to assess baseline performance. The single convolution block consists of a Conv2D layer with 32 filters and a kernel size of 3x3, followed by a MaxPooling2D layer to reduce spatial dimensions, thereby capturing essential features while minimizing overfitting. I chose the ReLU activation function to introduce non-linearity, and the subsequent flattening step converts the 2D feature map into a 1D tensor suitable for the dense layers. A fully connected layer with 256 neurons and ReLU activation captures high-level patterns before the final output layer, which uses a sigmoid activation for binary classification. To optimize the model, I used the Adam optimizer, known for its adaptive learning rate, and the binary cross-entropy loss function, appropriate for two-class problems. The images were rescaled by 1/255 to normalize pixel values, improving training stability. Additionally, I utilized a batch size of 32, balancing memory usage and training speed, and ran the model for 15 epochs to allow sufficient learning without overfitting. The model was trained using the ImageDataGenerator for real-time data augmentation, with separate generators for training and validation to maintain data consistency and comparability.

The model likely overfits after around 7 epochs, as evidenced by the increasing gap between training and validation accuracy and the rising validation loss. This is common in simple models trained for too many epochs. Introducing techniques like dropout, early stopping, or using a more complex model might mitigate this overfitting. Additionally, data augmentation or a more sophisticated CNN architecture might help improve generalization. The final model achieved a training accuracy of 0.9432 with a loss of 0.1506, while the validation accuracy was 0.8218 with a validation loss of 0.5972, indicating that despite high training performance, the model's generalization to new data remained somewhat limited.

##Two-Layer CNN (With Dropout)
To improve the performance and mitigate overfitting observed in the previous model, I designed a more robust CNN architecture with two convolutional layers and incorporated dropout. The input layer processes the 50x50x3 images and then the first convolution block consists of a Conv2D layer with 32 filters of size 3x3, followed by a MaxPooling2D layer to reduce the spatial dimensions while preserving key features. The second convolution block increases the filter count to 64, leveraging deeper feature extraction, followed by another MaxPooling2D layer. After flattening the output from the convolutional layers, a fully connected dense layer with 256 neurons and ReLU activation learns high-level representations. To address overfitting, I included a dropout layer with a rate of 0.5, which randomly drops half of the neurons during training, forcing the model to learn more general features. The output layer uses a sigmoid activation function for binary classification. The model was compiled using the Adam optimizer, chosen for its adaptive learning rate, and binary cross-entropy loss, appropriate for binary outcomes. The data was preprocessed by normalizing pixel values to the [0, 1] range using ImageDataGenerator. Training and validation data were loaded in batches of 32, and the model was trained for 15 epochs to balance learning progression with the risk of overfitting.

The addition of a second convolutional layer and dropout has notably improved the model's ability to generalize, as seen by the reduced gap between training and validation accuracy and the more stable validation loss curve. This indicates that the model is less prone to overfitting, likely due to the added model complexity and the dropout regularization. The fluctuations in validation accuracy early on suggest that the model initially struggled to learn generalized patterns, but eventually stabilized as training progressed. The final model output demonstrated a training accuracy of 0.8726 with a loss of 0.3101, while the validation accuracy reached 0.8431 with a validation loss of 0.3882, indicating a more balanced performance compared to the simpler model.

## Four-Layer CNN (With Dropout)
To further enhance the model's ability to capture complex patterns and improve generalization, I developed a deeper CNN architecture with four convolutional layers and dropout. The model starts by processing the 50x50x3 input images through four consecutive convolution blocks, each increasing in filter count (32, 64, 128, 256) to progressively learn more abstract and detailed features. After each convolutional layer, a MaxPooling operation reduces the spatial dimensions, preserving essential patterns while minimizing computational complexity. To prevent overfitting, a dropout layer with a rate of 0.5 is incorporated after the fourth convolution block. The flattened feature map is then passed through a dense layer with 512 neurons and ReLU activation to capture high-level representations before the final output layer, which uses a sigmoid activation for binary classification. This architecture, with its increased depth and dropout regularization, aims to balance model complexity with generalization.

The increased model complexity with four convolutional layers and dropout has significantly improved the model's capacity to capture complex patterns. The dropout layer helped mitigate overfitting compared to previous models. The occasional spikes in validation loss and accuracy indicate that the model might still be sensitive to certain batch variations or noise in the data. Despite these fluctuations, the overall trend indicates a well-trained model with improved generalization compared to previous attempts. Fine-tuning the dropout rate or implementing early stopping could help smooth out the fluctuations. The final model achieved a training accuracy of 0.8672 with a loss of 0.3214, while the validation accuracy reached 0.8431 with a validation loss of 0.3649, indicating a well-balanced performance between training and validation sets.

## Adding Batch Normalization and Early Stopping
Lastly, I introduced Batch Normalization and Early Stopping in the training process to try and reduce overfitting even more. Batch normalization was added after each convolutional layer to stabilize and accelerate training by normalizing the output, reducing internal covariate shift. Early stopping was configured to monitor validation loss, automatically halting training if the loss did not improve for 5 consecutive epochs, and restoring the best weights from the epoch with the lowest validation loss. The model was set to train for up to 30 epochs to allow sufficient learning, while early stopping ensured that the model would not overfit. The combination of batch normalization and early stopping aimed to produce more stable training by smoothing convergence, improving generalization by preventing overfitting, and yielding higher accuracy with more consistent validation performance.

The training and validation accuracy graphs show that the model effectively learns from the training data, with training accuracy starting at 0.81 and gradually increasing to 0.88 by epoch 12. This consistent improvement indicates that the model is fitting the training set well. However, the validation accuracy initially rises to around 0.84 at epoch 1, but then fluctuates significantly in the later epochs, with a notable drop to 0.69 at epoch 10. These fluctuations suggest that the model struggles to maintain consistent performance on unseen data, indicating potential overfitting. The training loss decreases steadily from 0.50 to 0.27, reflecting consistent learning and better fit to the training data. In contrast, the validation loss shows an initial decrease, reaching around 0.3 by epoch 6, but then suddenly spikes at epoch 8, with a loss of 2.1690, before decreasing again. Another smaller spike occurs at epoch 11, where the loss reaches 1.1023. These sudden increases in validation loss indicate that the model tends to overfit at specific training points, potentially due to batch variability or learning overly complex patterns that do not generalize well.

## Conclusion
In this study, I explored various convolutional neural network (CNN) architectures to classify breast histopathology images as normal or infected, progressively increasing model complexity by adding convolutional layers, dropout, batch normalization, and early stopping to enhance performance and reduce overfitting. The original dataset contained 277,524 images, and due to its large size, I used a 5% sample to ensure efficient training, resulting in 9,792 non-infected and 3,817 infected images, which were split into balanced training and validation sets. Starting with a one-layer CNN, the model achieved a training accuracy of 0.9432 and a validation accuracy of 0.8218, but showed signs of overfitting after around 7 epochs. To improve generalization, I implemented a two-layer CNN with dropout, which increased validation accuracy to 0.8431 and reduced the validation loss to 0.3882, demonstrating better performance than the simpler model. Further enhancing complexity, I developed a four-layer CNN, which captured more complex patterns while mitigating overfitting through dropout, achieving a training accuracy of 0.8672 and a validation accuracy of 0.8431, with a validation loss of 0.3649. To stabilize training and improve consistency, I introduced batch normalization after each convolutional layer to normalize outputs and reduce covariate shifts, along with early stopping to prevent overfitting by monitoring validation loss and halting training when improvements plateaued. The model, set to train for up to 30 epochs, stopped at epoch 12 due to early stopping, achieving a final training accuracy of 0.88 and a validation accuracy of 0.84, indicating that increasing model complexity combined with regularization techniques led to improved generalization and more consistent validation performance, though some fluctuations remained, suggesting further fine-tuning could enhance robustness.
